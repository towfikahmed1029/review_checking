{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "rc = [\"\"\"This is my first experience with this type of product, so I don't know if my technique needs improvement. This worked very well on surfaces inside my house, the fine gray house dust just went away with a quick press and remove of this product. In my wife's car, it didn't seem to have enough stickiness to pull away the lint and dust. I suspect that some type of sealer for the plastic surfaces may have been used when she had the car detailed a while back. I remember just a few days after the detailing, there was a sticky feel to the dashboard and other interior surfaces. Even blue painters tape couldn't pull away the dust however, so it's not the fault of this product. So be aware it may not work on some surfaces that have been treated with \"sealers\".\"\"\"]\n",
    "with open('rew.csv', 'w',newline='') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(('Review',))\n",
    "    writer.writerow(rc)\n",
    "mydata = pd.read_csv('rew.csv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  This is my first experience with this type of ...   \n",
       "\n",
       "                                     Cleaned Reviews  \n",
       "0  This is my first experience with this type of ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Cleaning the text in the review column\n",
    "mydata['Cleaned Reviews'] = mydata['Review'].apply(clean)\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Md Alamin\n",
      "[nltk_data]     Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Md Alamin\n",
      "[nltk_data]     Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Md Alamin\n",
      "[nltk_data]     Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "      <td>[(first, a), (experience, n), (type, n), (prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  This is my first experience with this type of ...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  This is my first experience with this type of ...   \n",
       "\n",
       "                                          POS tagged  \n",
       "0  [(first, a), (experience, n), (type, n), (prod...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "mydata['POS tagged'] = mydata['Cleaned Reviews'].apply(token_stop_pos)\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "      <td>[(first, a), (experience, n), (type, n), (prod...</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  This is my first experience with this type of ...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  This is my first experience with this type of ...   \n",
       "\n",
       "                                          POS tagged    Lemma  \n",
       "0  [(first, a), (experience, n), (type, n), (prod...    first  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        return lemma_rew\n",
    "\n",
    "mydata['Lemma'] = mydata['POS tagged'].apply(lemmatize)\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "# function to calculate subjectivity\n",
    "def getSubjectivity(review):\n",
    "    if review== None:\n",
    "        return 0.0\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "    # function to calculate polarity\n",
    "def getPolarity(review):\n",
    "    if review== None:\n",
    "        return 0.0\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "# function to analyze the reviews\n",
    "def analysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my first experience with this type of ...</td>\n",
       "      <td>first</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review    Lemma  Subjectivity  \\\n",
       "0  This is my first experience with this type of ...    first      0.333333   \n",
       "\n",
       "   Polarity  Analysis  \n",
       "0      0.25  Positive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data = pd.DataFrame(mydata[['Review', 'Lemma']])\n",
    "fin_data['Subjectivity'] = fin_data['Lemma'].apply(getSubjectivity) \n",
    "fin_data['Polarity'] = fin_data['Lemma'].apply(getPolarity) \n",
    "fin_data['Analysis'] = fin_data['Polarity'].apply(analysis)\n",
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1\n",
       "Name: Analysis, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_counts = fin_data.Analysis.value_counts()\n",
    "tb_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral    1\n",
       "Name: Vader Analysis, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# function to calculate vader sentiment\n",
    "def vadersentimentanalysis(review):\n",
    "    if review == None:\n",
    "        review = \"\"\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "fin_data['Vader Sentiment'] = fin_data['Lemma'].apply(vadersentimentanalysis)\n",
    "# function to analyse\n",
    "def vader_analysis(compound):\n",
    "    if compound >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif compound <= -0.5 :\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "\n",
    "fin_data['Vader Analysis'] = fin_data['Vader Sentiment'].apply(vader_analysis)\n",
    "\n",
    "\n",
    "fin_data.head(9)\n",
    "vader_counts = fin_data['Vader Analysis'].value_counts()\n",
    "vader_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
